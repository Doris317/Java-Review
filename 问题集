1、cpu数量和线程池数量的关系
	cpu密集型的程序，线程池数量设置位n+1（n为cpu数量）
	IO密集型的程序，线程池数量设置为2*n+：因为线程会阻塞等待io通信，此时cpu资源是闲置的，要充分利用
	但是正规的线程设置：线程数 = （1+I/O耗时/cpu耗时）*cpu核数
	
2、运行时注解和编译时注解
	每个注解都对应一个RententionPolicy，由其来指定注解的保存范围
		RententionPolicy.Source：标记该注解仅保存到源码中
		RententionPolicy.Class: 标记该注解可以保存到编译后的class文件中，但是运行的时候就找不到了
		RententionPolicy.Runtime:标记该注解可以一直保存到代码运行时，可以根据反射去获取
	所以，编译时注解和运行时注解首先保存阶段不一样
		  其次，原理不同：编译时注解是通过AbstractProcessor或者APT获取而运行时注解的原理是通过反射去获取
		  第三，编译时注解可能会产生新的java源文件而运行时注解只需要自定义注解器
		  第四，反射性能比较低，而编译时注解对性能没什么影响

3、redis的主从节点之间都有哪些区别，怎么切换
	redis是一个基于内存的单线程的kv存储结构的非关系型数据库，因为存储在内存中，所以当服务器关闭，宕机容易导致数据丢失，所以需要持久化。
	主从复制：目的是为了实现数据的持久化，可用性，分区容错性，当某台机器宕机的时候可以用从服务起来代替主服务器继续工作，所以要保证主从服务器之间的数据一致性。
	Redis的主从复制是基于异步的但是实现了最终一致性的复制模式。
		redis的主从复制的数据流向是单向的，只能由主服务器写向从服务器。
			全量复制：在从服务器启动初始化的时候会向主服务器发送一个sync或者psync的请求，主服务器会fork一个进程来写RDB文件，并把在写文件过程中的主进程的请求输入到缓冲区中。
					  当主进程的rdb文件写完后，会发送rdb文件给从服务器，然后将输入缓冲区的命令发送给从服务器。
					  从服务器接收到rdb文件后，会清空自己的数据库状态，加载rdb文件。加载完rdb文件根据配置决定是否bgwriteaof，然后再接收服务器发送的写命令进行写执行。
	异步复制，但是实现了最终一致性。分为全量复制和增量复制两阶段
			  redis2.8之前是通过全量复制来实现数据库的主从复制的，当从服务器挂机重连之后给主服务器发送sync命令，此时重新进行全量复制，会造成各种资源浪费（
				比如rdb文件的写并不是在原来的文件上写的，而是新建一个临时文件，写好之后再去替换原来的rdb文件。
				rdb文件的传输是需要消耗主从带宽的
				rdb文件的bgsave需要主服务器的主进程fork出一个子进程去处理，子进程是拥有父进程内存空间的副本的，因此也占内存）
			redis2.8以后采用全量复制加增量复制的模式，来提升主从节点的数据传输效率。
					 主节点有一个运行id，维护一个复制堆积缓冲区和一个偏移量。
						从节点向主节点发送psync命令的时候，主节点将自己的id和offset发送给从节点
						每次主节点向从节点发送命令的时候，会将命令同步存储到缓冲区，并修改offset的值（缓冲区是一个先进先出的队列）
						从节点每次收到命令并更新自己维护的位移量
					当从节点断线重连后，向主节点发送psync命令并携带主节点的id和自己的offset
						主节点会根据id和offset来判断offset的后的数据是否存储在缓冲区内，如果是，发送continue，从offset开始传输命令；如果不是，重新开始全量复制
	redis的主从模式分为一主一从，一主多从和多级主从。
	主从之间通过心跳包机制来保活，主节点每10秒给从节点发送一次ping消息；从节点每一秒给主节点发送一次pong消息（包含offset）。此时如果主服务器发现从服务器的offset和自己的不匹配，就会补发数据
	
	主从切换的方式：1、手动 slaveof NO ONE来将从服务器设置为主服务器，其他从服务器重新设置主服务器为新的从服务器
					2、通过哨兵模式
					
	哨兵模式：其实哨兵也是一台redis服务器
		  哨兵与主从节点间建立两条连接：命令连接和订阅连接
		  一个哨兵可以监控多个节点，一个节点也可以被多个哨兵监控
		  哨兵的工作：通过命令连接给节点每10秒发送info命令去获取节点信息：主节点回复自己的运行id和从节点信息；从节点回复自己的运行id，角色和复制数据的offset量
					  通过命令连接向连接的节点的sentinel:hello频道发送自己的端口号，运行id和配置纪元（用于选举leader）
					  通过订阅节点的sentinel:hello频道来获取其他哨兵节点的信息，与其他哨兵节点建立连接（哨兵节点之间只有命令连接）
				监控：每1秒向建立命令连接的节点发送ping消息，如果超过配置时间内未收到节点的回复信息，就标记该节点主动下线（主动下线只是针对这一个哨兵节点的）
					  当一个哨兵节点发现主节点主动下线，他会给其他哨兵节点发消息来询问他们对该节点的判断。如果超过设置的数量的哨兵节点认为该主节点主动下线，该哨兵节点就在自己的实例结构内设置主节点为客观下线。
					  当一个哨兵节点发现主节点客观下线之后，会开始问询其他哨兵节点，带上自己的运行id，让其他哨兵节点选举自己作为leader，用于执行故障转移。（每个哨兵节一个纪元内只有一次投票权，且投了就不能更改了，超过半数的节点投票的节点称为leader）
				故障转移：leader根据主节点的从节点信息：选择连接着的，优先级高的然后offset数值大的从节点作为新的主节点，并向其他从节点发送消息，让他们设置该节点为主节点，旧的主节点上线的时候也会曾为该新的节点的从节点
		
	redis的集群
	redis的集群是用来实现高并发以及可用性的
	每个节点都是一个单机节点，通过配置来确定是否开启自己的集群
	配置好集群服务的节点通过cluster meet ip port来向某节点发起握手请求（集群的缺点是缺少节点自动发现机制，需要主动去握手节点）
	比如节点A发现节点B，给节点B发送一条meet消息，并为其建立一个clusterNode结构保存在自己的clusterState.Nodes字典里
	B接收到meet消息后给A建立一个cluserNode结构保存在自己的cluster.Nodes字典里,然后给A回复一条pong消息
	A接收到pong消息后知道节点B已经连上，回复一个ping消息，并利用gossip协议将节点B的存在通知给集群中的其他节点
	
	redis集群是通过分槽slot来确定每个节点的工作范围的，一共有16384个槽，当全部槽有节点负责的时候称为集群上线，否则称为集群下线
	每一个槽位对应数据库的key，通过每个key通过CRC16校验后对16384取模来决定放置哪个槽
	每个节点维护一个clusternode.slots数组通过二进制位来确定自己负责的槽位，同时维护一个clusterState.slots数组来维护集群中的槽位分配情况，该数组的每一项是指向负责本槽位的clusternode的指针
	
	读取数据的时候，会根据一致性hash算法来确定数据所在的槽位，查询clusterstate.slots数组来判断指针是否指向自己，如果是，去执行请求操作；如果不是返回moved错误：moved slot ip port，让客户端重定位节点并重新申请
	其实除非是单机版的redis集群，否则的话moved错误是隐形的，moved错误的实际原理是：让客户端通过给定端口号和ip的连接进行通信，如果还未连接，就先建立连接，再通过socket通信
	
	集群的主从复制：一个主节点可以有多个从节点，主节点负责处理槽，是读写分离的
					节点周期性向随机个节点中（最久未联系的）发送ping消息，如果对方超时未回复，就在自己维护的clusterNode中标记该节点为疑似下线节点，并通过消息通知给其他节点，每个接收到该类型消息的节点都会标记在自己的clustersState中给该节点标记疑似报告
					当某节点发现有半数以上的节点标记为怀疑下线节点，就标记该节点给下线节点，并广播一条fail消息来通知所有主节点该主节点下线
					第一个发现自己复制的主节点为下线节点的节点会向所有主节点广播一条请求来申请投票自己作为新的主节点，每个处理节点都有一次投票权，先来先得
					被选中的从节点将进行故障转移：
						1、首先它将主节点处理的槽指派给自己
						2、然后广播一条pong消息来通知所有节点它已经替换成为新的主节点
						3、然后进行槽管理和客户端申请的执行
	
	重新分片：关键点是槽对应的键值对的转移

4、redis单机大约能撑多少qps

5、zset底层的数据结构，什么时候发生这些数据结构之间的切换
	redis是一个基于内存的单线程非关系型数据库
	redis是一个kv型的存储结构，key值是字符串，而value有五种类型：字符串型、hash型、列表型、集合型和有序结合型
	字符串型的数据结构：字符串和基本数据类型
	列表型的数据结构：链表结构，压缩链表ziplist和双端链表linkedlist
	hash型：ziplist或者hashtable。
	集合型：intset或者hashtable。
	有序集合型：zset的底层实现是skiplist（跳表）

6、跳表的时间复杂度按照member和score查询的时间复杂度分别是多少
	O（1）

7、给定大量url，如何判断重复
	
8、maven dependency和dependencyManagement的区别

9、kafka的高可用模型以及partition选举算法，如何保证顺序消费

10、redis的过期键
    redis通过expire key time或者pexpire key time可以给一个键设置生存时间
		字符串键值对还可以通过setex key time value在创建键值对的时候设置生存时间
		可以通过ttl key来查询键的剩余时间
	
	过期键的删除策略：1）定时策略，对每一个设定过期时间的键建立一个定时器，定时删除，开销大。对cpu资源不友好
					  2）惰性删除：每次访问或者特殊设置的时候setnx，判断当前键是否过期，过期删除，没过期的时候执行。对内存不友好
					  3）定期删除：周期性对数据库的进行随机检测，周期和随机算法是可以配置的
				redis的过期键删除采用的是惰性删除+定期删除。定期删除是利用redis的时间事件serverCron函数（该函数每100秒执行一次）执行：固定时间内顺序遍历数据库，对每个库随机检测n个键，下一次触发从上一次停止的地方继续进行
				
	
13、索引失效：
	首先可以通过explain查询执行语句，通过key这一列来查询该语句所用的索引
	1、当like模糊索引的时候，开头是通配符，不会使用索引（会进行全表扫描）
	2、如果使用or，or的前后必须都是索引，否则索引失效
	3、使用<>,not in, != 也会进行全表扫描，所以索引失效，可以替换成> or  <
	4、如果使用组合索引没有按照最左原则也会使索引失效
	5、对索引字段进行计算或者使用函数的时候，索引也会失效
	6、全表扫描速度优于索引的时候，会使用全表扫描，索引失效：
	7、对索引进行隐式数据类型转换的时候，比如char变量未使用‘’时，索引失效

14/网卡收到一条数据到进程处理数据，中间经历了什么

15、大数据量下，快排和堆排的对比（缓存命中率的对比）
	快排和堆排都是一个不稳定的排序方式，两者的平均时间复杂度都是O(nlogn)
	堆排时间复杂度比较稳定，快排最快的时间复杂度是O（1）而最差是O（n*n）
	但是堆排的性能在大数据缓存下比较低，首先堆排不是顺序式访问的，它是跳跃式访问的，这对cpu的读写其实是有影响的，而快排是局部顺序性的
	其次，堆排的每一次交换之后都得重新进行堆的构建，会打破原有数据的有序排列
	
	所以快排的缓存命中率比较高

16、缓存失效和替换原理
	缓存失效：
	
17、32位系统运行大于4g的的程序，如何寻址

18、线程池的底层实现原理
	ThreadExecutorPool()：其实就是消息队列异步架构，池化技术。
		饱和策略有：直接丢弃，丢弃并抛出异常，丢弃最老的任务，由调用者直接执行
		底层worker是hashset结构，旨在自动消除重复
		ExecutorService service的四种线程池：Executors.newSingleThreadExecutor();
											 Executors.newCachedThreadPool();
											 Executors.newFixedThreadPool();
											 Executors.newScheduledThreadPool()；
		阻塞队列：数组有界、链表无界、优先级无界阻塞队列、延迟阻塞队列、同步阻塞队列：一个不存储元素的阻塞队列。

19、如何中断线程，await和sleep的区别
	调用线程的interrupt()方法来中断线程：该方法只是设置中断标志并不会真正的去中断线程，所以要配合异常来处理
		InterruptedException是线程自己从内部抛出的，并不是interrupt()方法抛出的。对某一线程调用interrupt()时，如果该线程正在执行普通的代码，那么该线程根本就不会抛出InterruptedException。但是，一旦该线程进入到wait()/sleep()/join()后，就会立刻抛出InterruptedException。
	await方法是进入等待队列，释放了锁。是Object类方法
	sleep是不释放锁的，属于Thread类方法，seleep唤醒后是进入可运行队列
	yeild()是暂停当前线程，如果没有其他线程抢占cpu的话就继续执行
	join()是等待join的线程结束后，当前线程才会继续执行


21、短URL的实现

22、数据库主从复制的时候，如何保证挂掉那段时间的数据
 首先主从复制分为异步复制和半同步复制和全同步复制。
 异步复制：就是主服务器执行完客户端提交的事务后就直接反馈给客户端，并不关心从服务器的状态。后面异步刷新到从服务器。如果主机宕机之类的，从库的数据就不能保证一致性
 半同步复制：就是主服务器执行并提交，然后等待从服务器至少有一个收到relaylog之后再回复ACK，如果在从服务器还未监听到事件的过程中宕机，还是会出现数据不一致性
 全同步复制：主机执行不提交，等确定从服务器收到relaylog后再执行提交并回复。问题是：如果从服务器收到并执行之后，主机自己回滚事务，还是会存在数据的不一致性。

23、作为调用方和被调用方如何避免缓存雪崩
	缓存雪崩：是指某一时刻下，大量的缓存突然失效，使得大量的请求透过缓存到后台数据库，造成后台系统压力（这里不是指同一个数据而是多个数据）
		解决办法：在设置缓存过期时间的时候加上随机数，这样减少同一时间失效的缓存数；加锁，让一个线程写数据库并同步到缓存，其他线程都缓存数据，没有的话就堵塞；设置热点数据不过期
	缓存击穿：指某缓存未命中会取访问数据库，问题是：该数据的缓存失效，可能会使大量线程涌入后台，并发读写，造成后台系统的压力
	     解决办法：加锁，让一个线程写数据库并同步到缓存，其他线程都缓存数据，没有的话就堵塞；设置热点数据不过期
	缓存穿透：对缓存没有数据库也没有的数据的访问
		解决办法：对于访问的key值如果数据库也不存在，也进行缓存，缓存为特殊字符，缓存时间设置短一点（避免影响后续正常使用），当客户端发现是特殊字符不做处理
				  加拦截器去拦截非法登入或者非法请求的账户

24、抢红包：如何设计每个用户最多一分钟内只能抢五次红包
	利用redis的过期键（setex）
	当不存在事件key的时候，创建key，value设置为1，并同时设置过期时间
	接下来每次抢红包先取v值判断，没超过规定值就可以抢，超过规定值就拒绝其抢红包，等过期之后再重设
	
25、如何生成不重复的订单号

26、分布式锁如何设计

27、java的虚引用是做什么用的
	Java的引用分为强引用、软引用、弱引用和虚引用
	强引用：比如new 创建对象之类的引用是强应用，被持有强引用的对象是不会被垃圾回收的
	软引用：只有当内存不足的时候，才会回收该对象。所以可以用作内存敏感的缓存
	弱引用：每一次GC的时候都会回收该对象，可以用来做映射，比如ThreadLocal
	虚引用：随时都可能被回收掉，用于通知关联对象做最后的清理工作。目的是检测内存对象是否被删除。
			如果JVM要回收该对象，会将它加入一个虚引用的引用队列，然后程序可以通过是否存在在引用队列里来决定是否要做清理工作

29、分库分表的维度和划分算法以及出现的问题

30、缓存击穿的解决方式？怎么加锁？什么时候选择本地锁，什么时候选择分布式锁？

31、tcp四次挥手，为什么等2ML
	客户端给服务器端发送fin标志为1的序号为x的包来通知对方要进行关闭连接，此时客户端不会再接收新的请求
	服务器端收到请求后，因为有请求可能还在处理，所以他先回复一个ack标志为1，序号为x+1的确认包给客户端，然后进入等待关闭状态
	服务器端处理好残余任务的时候，向客户端发送fin标志为1，序号为y的fin包进行最后的关闭确认
	客户端在接收到服务端的关闭通知的时候，给服务端回复一个ACK

	2ML：两个最大报文的生命周期
	   目的：1）可能客户端的ACK并没有按时到达服务端，所以服务端会重发fin消息给客户端进行关闭确认（如果不等待的时候，收到fin包，因为客户端已经关闭，所以会发送一个rst包，此时服务端的状态就会异常）
			2）清理旧连接的包以免影响新的连接。如果不等待的话，可能ack超时到达服务端，然后服务端先重发fin给客户端之后又收到了ack关闭连接了，但是新起的连接可能会一开始就收到一个fin通知

32、开灯的算法

33、如何保障请求的执行顺序

35、zookeeper的作用

36、mybatis如何分页，如何设置缓存，mysql分页
	1、利用mysql的limit查询的时候就进行分页
	2、对查询结果保存在容器或者集合里，然后利用sublist对集合进行去子集
	3、拦截器分页（责任链模式）
	
37、分布式session一致


39、redis的持久化：
	两种方式;RDB和AOF
	RDB持久化是保存的redis的数据库状态而AOF文件保存的是每一条写命令
		当手动调用save/bgsave命令时，前者是当前进程堵塞去写rdb文件；而后者是从父进程中fork出一个子进程来根据父进程的临时性快照写rdb文件。（子进程持有和父进程一样的数据副本）
		自动执行：一般是通过save 300 1之类的设置，在servercron函数（redis的时间事件）周期性执行的时候去读dirty计数器来决定是否刷盘
	AOF文件：需要配置appendonlyfile yes
			 每当有写命令发生的时候，先写入到aod_buf缓冲区（命令追加）
			 然后再根据配置项决定是同步刷盘还是定时刷盘以及永不刷盘来维护数据一致性。一般是选择定时刷盘;appendfsync always\appendfsync everysec\appendfsync no
	rdb文件因为只保存数据库的状态，所以数据量比较小，加载比较快，缺点是它是特殊的二进制文件，适用于大数据量，但不适用于移植，平台性强。而且每次创建rdb文件都涉及到fork子进程，开销较大，且数据的实时性没有aof高，因为aof丢失的可能只是一秒的写命令，所以aof一般适用于冷缓存
	aof文件要记录每一条写命令，体积比较大，加载的时候需要创建一个不连接网络的伪客户端执行命令来加载数据，耗时较长
	
	AOF重写：因为aof文件的体积较大，所以可以通过手动或者自动触发aof重写来改善优化
			aof重写就是根据当前的数据库状态来创建写命令，然后用重写文件替换aof文件。
			手动触发：直接调用bgrewriteaof命令。
·			自动触发：根据auto-aof-rewrite-min-size和auto-aof-rewrite-percentage参数确定自动触发时机

40、redis的分布式锁

41、排序算法：
	1）冒泡排序：平均时间复杂度是n平方，原理是进行n趟排序，每趟排序都两两交换：稳定
	2）选择排序：平均时间复杂度还是n平方，进行n趟寻找，每趟遍历选出最小的元素插入队头：不稳定
	3）插入排序：平均时间复杂度还是n平方，进行n趟排序，每趟都是将新的元素插入到前有序队列中：稳定
	4）归并排序：复杂度是logn，进行分治解然后归并 稳定
	5）堆排序：先建造堆logn，然后根据将堆顶元素依次插入队首或者队尾，每次poll出一个元素的时候要重新建堆  不稳定
	6）快排：就是选择一个基数，将比它小的移动到左边，比他大的移动到右边，logn 不稳定
	
42、 ThreadLocal的实现：为了线程数据隔离
	ThreadLocal用来管理线程的本地变量的副本，每一个线程内部都有一个ThreadLocalMap对应他自己的本地变量的副本，这个副本由ThreadLocal管理。
	每次都根据当前的线程找到其对应的ThreadLocal map然后再获取变量的value。
	ThreadLocalMap的键是弱引用而value是强引用，在没有内部强引用或者内存不够进行Gc的时候会回收弱引用的对象，所以为了避免内存泄漏问题，最好是用完记得调用remove函数主动释放空间
			与hashMap不同的是，这里的map是没有next指针的，因此就不是通过链表来解决hash冲突，这是通过开放地址线性探测法去解决hash冲突的。
			所以最好一个ThreadLocal只存放一个变量副本
			
43、HashMap的扩容：
	1.7：数组+链表：
		采用头插法，将元素放在链表头部，倒置链表容易形成闭合环路，造成线程不安全问题
	1.8：数组+链表+红黑树：
	    因为链表的查询效率是O（n）,所以优化为当链表的个数大于8的时候，再添加元素就开始建立红黑树，以空间来换取时间效率
		JDK7里面是先判断table的存储元素的数量是否超过当前的threshold=table.length*loadFactor（默认0.75），如果超过就先扩容，
		在JDK8里面是先插入数据，插入之后在判断下一次++size的大小是否会超过当前的阈值，如果超过就扩容。 （扩容的时候也不再采用头插法而是保留了元素的原来顺序）

 ConcurrentHashMap的实现
	jdk1.7的时候是通过分段锁：
		将数据分成segment，每一个segment又包含一个hashEntry数组，而每一个数组项又是一条链表。分段加锁；但是对于跨段的锁，需要按顺序申请和释放
		扩容：segment数组大小是不变的，固定为16个。所以扩容指的是HashEntry数组的扩容，类似于hashmap的扩容原理，扩容为两倍大小。在扩容结束，使用新表的索引来代替旧表。就算出现安全问题也只是单一段上的，但是并发度是segment数，较低
	jdk1.8是通过CAS+Synchronized实现的：
		抛弃了原来的segment（继承自可重入锁），优化了锁粒度，并发度更高
		锁是table的元素级别的，即链表头节点的，所以每一个table的读写都不会影响到其他table，并发度更高。
		但是扩容的时候不能分段操作，要整表操作，所以提出forwardnode的概念。类似于设置标志位，读写的时候发现这个标志位就去帮忙扩容复制，否则的话读旧表数据没有问题，写是直接阻塞的。
		不需要重新计算hash，只要根据新增的hash位是0/1来决定是原位置还是原位置加原容量：新增的1bit是0还是1可以认为是随机的，因此resize的过程，均匀的把之前的冲突的节点分散到新的bucket了
		但是对于读取map的size（）其实还是存在不一致性问题。可以通过加版本号，每次修改就会去修改版本号，比较版本号发现是否一致的办法来解决。

44、如何保证数据库和redis之间的数据一致性
	首先要知道redis只是用于做数据的缓存的
	所以：1）可以读写分离：读数据的时候通过缓存去读，不存在读db并写入缓存；写数据的时候直接写入db然后同步到缓存
		  2）对于实时性要求比较低的数据，可以通过写redis，然后异步刷新到数据库的方式（比如历史排名之类的）；而对于实时性要求比较高的数据可以直接写db然后缓存到redis中
		  3）对于并发度比较高的时候可以缓存异步刷盘，但是请求较少的时候可以实时更新db
		  4）利用订阅发布模式，redis通过订阅mysql的binlog，一旦binlog的记录有更新，redis可以收到消息并同步执行

45、Mybatis编程步骤

46、如果实体类中的属性名和表中的字段名不一样，怎么处理
	可以通过别名处理，就是在sql语句中定义字段名，让字段名和实体类的属性名一致
	可以通过映射（resultMap）
	一般字段名是下划线格式，而实体类的属性名是驼峰命名法

47、XML映射文件有Mapper接口与之对应，Mapper接口的工作原理是什么？Mapper接口里的方法能重载吗
	Mapper接口的工作原理是为了定义sql语句的执行方法
	接口名的全限定名是xml文件的namespace；方法名是statement的id； 而方法参数是sql语句的执行参数
	不能重载，因为调用sql语句时是根据接口的全限定名+方法名来定位statement
				Mybatis的原理是利用jdk代理为接口生成代理对象，去寻找statment执行。

48、 Mapper接口绑定的方式以及如何获得自增的值
	 注解绑定 @Mapper @Select（{}）
	 xml绑定：与接口在resource下的同一个路径下的同名.xml文件
	 可以通过策略设置，<insert id="add" parameterType="com.dsm.domain.Blog" useGeneratedKeys="true" keyProperty="id">

49、在 Mapper 中如何传递多个参数
	利用map传参数、
	利用对象的属性批次传参数、
	直接传多个参数（@param）
	

50、 Mybatis的缓存机制
	一级缓存：是sqlsession级别的缓存，每个sqlsession共享自己的缓存，但是会话结束后缓存就失效了
	二级缓存：因为mybatis一般是与spring框架一起使用的，二级缓存是mapper级别的缓存。
			  通过setting name = "cacheEnabled" value = "true"来开启缓存，并在需要二级缓存的dao对应的xml中使用<cache>标签，注意开启二级缓存需要接口实现序列化
			  然后对于同一个命名空间下的缓存，多个sqlseesion可以共同访问
			  问题是：不同命名空间下有同一个数据表的缓存，可能会造成内存不一致性，所以一般二级缓存默认是禁止的

51、Mybatis 的 XML 映射文件和 Mybatis 内部数据结构之间的映射关系

52、Mybatis 都有哪些 Executor 执行器？它们之间的区别是什么？

53、HTTPs的加密过程：端口443
	通过非对称加密RSA算法申请公钥的时候，因为服务器可以通过私钥解客户端公钥加密的文件，而客户端是通过自己的公钥来解服务器加密的文件。客户端是没办法解密其他客户端的文件，但是对于服务器发送的文件所有客户端都能解开
	当某一客户端向服务器申请公钥的时候，因为无法通过公钥来确认服务器信息，所以容易被中间第三者劫持，这是第三者获取到客户端的公钥可以用来解密服务器的消息，然后发送自己的公钥和篡改后的消息给客户端。
	所以还会出现信息劫持和服务器抵赖的问题
	但是ssl是通过散列函数加密明文消息，rsa用于身份验证和生成对称密钥，然后通过对称密钥进行信息传输
	首先，客户端向服务器申请公钥
	  服务器将公钥和自己的信息发送给CA
	  CA通过散列算法加密明文信息，并加密签名发送给服务器
	  服务器将消息换发给客户端
	  然后客户端通过同样的hash算法解密明文信息并与自己收到的明文信息进行对比来验证服务器信息，并用CA的公钥解密签名信息，计算随机数作为密钥并用ca公钥加密传给服务器，同时用自己的密钥和对应的加密算法加密之前的通信信息作为验证信息发给服务器
	  服务器拿到信息，利用自己的私钥解密，得到随机数并计算自己的私钥，利用自己的私钥解密验证信息用于验证
	  然后开始通信

Spring：
1、IOC：控制反转
	代替由对象主动去创建自己的依赖对象实例，Spring将对象实例的创建权和对象间依赖关系的管理权交给了IOC容器，由IOC容器根据配置在运行时动态注入
2、DI：依赖注入
      运行时由IOC容器根据配置进行动态注入
	  bean的注入方式有：
		1）配置注入：构造器注入：<constructor-arg>注意无参构造，多参构造（构造函数的重载）
					 Setter注入：<property> 会根据传入参数的首字母大写的单词加上set去寻找注入（该注入需要对象有一个默认无参构造）
		2）注解注入：
		            @Resource：java注解，byName寻找，如果没有再根据byType查找，如果type有重复的话，可以根据@Qulifier（）指定的name进行匹配
					@Autowired spring注解，先byType查找，如果没有根据name查找 （byname：严格要求首字母大写）
3、bean的作用域
	1）singleon：spring默认的作用域，在容器启动的时候就会创建该实例，作用域是当前容器
	2）property：每次申请的时候就会创建一个对象实例（原型模式）
	3）request：每次请求会创建一个对象实例，当请求结束的时候自动销毁，作用域是当前请求
	4）session：每次开启一个session会话的时候会创建一个对象实例，会话结束就消毁，作用域是当前会话（会话中的多个请求共享该对象实例）
	5）global-session：一个serveletContext中只有一个对象实例
	
4、bean的生命周期
	1）启动的时候查找需要被spring管理的bean，进行实例化
	2）属性注入引用和值
	3）查找相关Aware接口进行方法调用
		（1）如果实现了BeanNameAware接口，调用setBeanName()方法传入bean的id
		（2）如果实现了BeanFactoryAware接口，调用setBeanFactory()方法传入该bean的factory
		（3）如果实现了BeanApplicationContextAware接口，调用setBeanApplicationContext()方法传入bean所在应用上下文
	4）如果实现了BeanPostProcessor接口，Spring将调用他们的postProcessBeforeInitialization()方法
	5）如果Bean 实现了InitializingBean接口，Spring将调用他们的afterPropertiesSet()方法。类似的，如果bean使用init-method声明了初始化方法，该方法也会被调用
	6）如果Bean 实现了BeanPostProcessor接口，Spring就将调用他们的postProcessAfterInitialization()方法。
	7）bean可以使用，直至应用上下文被销毁
	8）如果实现了disposableBean接口，Spring将调用它的destory()接口方法，同样，如果bean使用了destory-method 声明销毁方法，该方法也会被调用。
	
5、BeanFactory和ApplicationContext
   BeanFactory是spring的底层接口，主要管理bean的定义，读取bean的配置，负责bean的加载和实例化
				启动的时候加载bean，但不进行实例化，等到运行时才去实例化
				所以启动速度快，但是运行速度慢
	ApplicationContext实现了BeanFactory接口，继承了BeanFactory的功能，但是它特殊的是在启动的时候加载并实例化bean
				启动速度慢，但是能发现配置的问题。运行速度比较快
	除此之外，applicationContext还具有一些其他功能，包括：国际化（MessageSource）、访问资源和URL（ResourceLoader）、AOP以及消息响应和发送机制
   
6、ApplicationContext常用实现
	ApplicationContext最重要的两个子接口：
	1）ConfigurableApplicationContext：几乎所有的应用上下文都实现了该接口
		(1)ClassPathXmlApplicationContext:加载类路径下的上下文配置文件
		(2)FileSystemXmlApplicationContext：加载系统任意路径上的配置文件
		
	2）WebApplicationContext
	   XmlWebApplicationContext：用于web应用
	
7、Spring的事务
	是提供对数据库事务的支持，如果没有数据库连接的话，spring是没有事务操作的。spring事务的提交和回滚是通过数据库的binlog和relaylog来实现的
	spring的事务是利用AOP对方法进行拦截实现的
	分为：编程式事务和声明式事务（@Transactional（））
		编程式事务管理使用TransactionTemplate。
		声明式事务利用aop加@Transactional（），对目标方法执行前后进行拦截，将事务拦截的功能编织到目标方法种。在目标方法开始前声明一个事务，在目标方法完成后根据结果决定提交或者回滚。（跟编程式事务比起来，代码解耦合，前者硬编码。
			但是aop只能实现方法级别的事务而不能实现代码块的事务）
		默认情况下，如果被注解的数据库操作方法中发生了unchecked异常，所有的数据库操作将rollback；如果发生的异常是checked异常，默认情况下数据库操作还是会提交的。
spring的传播性
	共7种：
	1） PROPAGATION_REQUIRED：如果当前有事务，支持当前事务，如果没有就开启事务
	2） PRPAGATION_SUPPORTS: 如果当前有事务，就支持当前事务，如果没有，就以非事务执行
	3） PROPAGATION_MANDATORY：如果当前有事务，就支持当前事务，如果没有，就抛出异常
	4）	PROPAGATION_NEW：无论当前是否有事务，都开启新的事务，如果当前存在事务，把当前事务挂起。所以内层事务不依赖外层事务，内层事务的回滚是回滚内层事务，而外层事务的回滚也不会影响内层 JTATransactionManager
	5）	PROPAGATION_NOT_SUPPORTED：以非事务方式执行，如果当前有事务就挂起当前事务 JTATransactionManager
	6） PROPAGATION_Never：以非事务方式执行，如果当前有事务就抛出异常
	7） PROPAGATION_NESTED: 如果当前有事务，就嵌套事务执行，如果当前没有事务，就开启新事务：与new不一样的是，内层事务是依赖外层事务的，外层事务的回滚是会影响内层事务的回滚，即整个回滚（回滚到savepoint）DataSourceTransactionManager
Spring的隔离级别：
	1）ISOLATION_DEFAULT:数据库的默认隔离级别，mysql的是可重复读
	2）ISOLATION_READ_UNCOMMITED:读未提交，会出现脏读，不可重复读或者幻读
	3）ISOLATION_READ_COMMITED:读已提交，会出现不可重复读和幻读
	4）ISOLATION_REPEATABLE_READ：可重复读，会出现幻读
	5）ISOLATION_SERIALIZABLE：序列化，串行读取数据，保证了数据库的一致性
		 

9、spring如何解决循环依赖
	循环依赖是指创建bean实例的时候存在着依赖注入
	通过构造器注入的bean，是没有办法解决循环依赖的，只能抛出异常。在创建bean实例的时候，spring维护一个正在创建bean的容器，每次创建一个bean实例的时候先去检查该容器中是否有正在创建的该bean实例，如果有，就抛出异常
	通过setter注入的bean，只可以解决单例作用域的bean的循环依赖，其他的也只能抛出异常。spring是通过暴露已经完成构造注入还在进行其他工作的（比如setter注入）的bean的对象工厂来实现避免单例作用域的循环依赖的。主要实现过程是：在创建新的bean实例的时候，
	先去检查缓存中是否有对应的objectfactory，如果有，获取该工厂返回的getobject对象（正在创建过程中的bean）直接使用，如果没有的话，就重新创建，并将创建过程中的bean的objectfactory加入缓存池。

10、spring中的设计模式
	单例模式：例如：单例作用域的bean（spring并未考虑线程安全问题）
	原型模式：比如：prototype作用域的bean是在每次申请创建bean的时候重新创建一个bean实例
	观察者模式：ApplicationListener（注册事件通过监听事件来决定后续操作）
	工厂模式：beanfactory是根据给定的唯一标识符bean的id来创建bean实例
	代理模式：spring的aop面向切面编程就是通过运行时动态代理织入目标方法中的
	

11、AOP：面向切面编程
   OOP：面向对象编程，是垂直的，抽象出一组对象的共同属性，具有封装、继承和多态的特性
   AOP：横向切面；允许对程序进行事务管理，日志管理等，将常见的业务逻辑和系统服务分开。
	技术：jdk动态代理和CGLib动态代理
	     jdk动态代理：利用反射，通过实现了Invocationhandler接口的invoke方法并持有被代理类的对象来实现
					  缺点是：被代理类必须实现某个接口
		 CGLib动态代理：第三方库，实现了MethodInterecptor接口的intercept()方法利用回调来实现的
	知识点：
		切点：就是通知执行的点
		切面：
		连接点：切面上的所有点都可以作为连接点，而切点是就是织入的点
		织入：通过静态代理和动态代理技术将通知织入到某个切面的切点上
		通知：分为前置通知、后置通知（不管是否正常结束）、环绕通知、AfterReturning（正常结束带返回值的通知）、AfterThrowing（抛出异常后的结束通知）